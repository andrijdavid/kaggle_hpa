{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from pathlib import Path\n",
    "import PIL\n",
    "import cv2\n",
    "\n",
    "from utils import FocalLoss, f1\n",
    "from dark import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "MASKS = 'train.csv'\n",
    "\n",
    "PATH = Path('./')\n",
    "\n",
    "TRAIN = Path('train/')\n",
    "TRAIN64 = Path('train64/')\n",
    "TEST = Path('test/')\n",
    "\n",
    "SAMPLE = Path('sample_submission.csv')\n",
    "\n",
    "seg = pd.read_csv(PATH/MASKS)\n",
    "sample_sub = pd.read_csv(PATH/SAMPLE)\n",
    "train_names = list(seg.Id.values)\n",
    "test_names = list(sample_sub.Id.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_image4d(path:PathOrStr)->Image:\n",
    "    '''open RGBA image from 4 different 1-channel files.\n",
    "    return: numpy array [4, sz, sz]'''\n",
    "    path=str(path)\n",
    "    flags = cv2.IMREAD_GRAYSCALE\n",
    "    red = cv2.imread(path+ '_red.png', flags)\n",
    "    blue = cv2.imread(path+ '_blue.png', flags)\n",
    "    green = cv2.imread(path+ '_green.png', flags)\n",
    "    yellow = cv2.imread(path+ '_yellow.png', flags)\n",
    "    im = np.stack(([red, green, blue, yellow]))\n",
    "\n",
    "    return Image(Tensor(im/255).float())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = train_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'NoneType' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-64b6948ba0e7>\u001b[0m in \u001b[0;36mopen_image4d\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myellow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'NoneType' and 'int'"
     ]
    }
   ],
   "source": [
    "%time im = open_image4d(TRAIN/fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Image4C_ds(ImageMultiDataset):\n",
    "    def __init__(self, fns:FilePathList, labels:ImgLabels, classes:Optional[Collection[Any]]=None):\n",
    "        super().__init__(fns, labels, classes)\n",
    "    def __getitem__(self,i:int)->Tuple[Image, np.ndarray]: return open_image4d(self.x[i]), self.encode(self.y[i])\n",
    "    def _get_x(self,i): return open_image4d(self.x[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.data_block import _df_to_fns_labels\n",
    "fnames, labels = _df_to_fns_labels(seg, label_delim=' ', fn_col=0, label_col=1)\n",
    "test_fnames, _ = _df_to_fns_labels(sample_sub, fn_col=0, label_col=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = uniqueify(np.concatenate(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = ([0.485, 0.456, 0.406, 0.406], [0.229, 0.224, 0.225, 0.225])\n",
    "norm,denorm = normalize_funcs(*stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = get_transforms(do_flip=True, flip_vert=True, max_lighting=0.1, max_zoom=1.05, max_warp=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(sz=64, bs=64, is_test=False):\n",
    "    folder=TRAIN\n",
    "    test_ds=None\n",
    "    if is_test: \n",
    "        t_names = [TEST/f for f in test_names]\n",
    "        test_labels = [[classes[0]]] * len(test_names)\n",
    "        test_ds = Image4C_ds(t_names, test_labels, classes)\n",
    "    train, val = Image4C_ds.from_folder(PATH, folder, fnames, labels, valid_pct=0.2, classes=classes)\n",
    "    return ImageDataBunch.create(train_ds=train, valid_ds=val, test_ds=test_ds,\n",
    "                                 ds_tfms=tfms, tfms=norm, bs=bs, size=sz)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, val = Image4C_ds.from_folder(PATH, TRAIN, fnames, labels, valid_pct=0.2, classes=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12885  1254  3621  1561  1858  2513  1008  2822    53    45    28  1093   688   537  1066    21   530   210   902\n",
      "  1482   172  3777   802  2965   322  8228   328    11]\n"
     ]
    }
   ],
   "source": [
    "class_sample_count = array([12885,  1254,  3621,  1561,  1858,  2513,  1008,  2822,    53,\n",
    "          45,    28,  1093,   688,   537,  1066,    21,   530,   210,\n",
    "         902,  1482,   172,  3777,   802,  2965,   322,  8228,   328,\n",
    "          11])\n",
    "print(class_sample_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'weight' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-e6f9541c40a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWeightedRandomSampler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mwrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWeightedRandomSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'weight' is not defined"
     ]
    }
   ],
   "source": [
    "# from torch.utils.data.sampler import WeightedRandomSampler\n",
    "# wrs = WeightedRandomSampler(weight, len(weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = dark_small()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_learner(data, focal=False, fp16=False):\n",
    "    learn = Learner(data, arch , metrics=[accuracy_thresh, f1])\n",
    "    if loss: learn.loss_func=FocalLoss()\n",
    "    if fp16: learn.to_fp16();\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data(64, 128, True)\n",
    "learn = get_learner(data, focal=True, fp16=sTrue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 4e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "        \t/* Turns off some styling */\n",
       "        \tprogress {\n",
       "\n",
       "            \t/* gets rid of default border in Firefox and Opera. */\n",
       "            \tborder: none;\n",
       "\n",
       "            \t/* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "            \tbackground-size: auto;\n",
       "            }\n",
       "\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='8' class='' max='10', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      80.00% [8/10 13:29:57<3:22:29]\n",
       "    </div>\n",
       "    \n",
       "<table style='width:375px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy_thresh</th>\n",
       "    <th>f1</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.988141</th>\n",
       "    <th>0.933428</th>\n",
       "    <th>0.958701</th>\n",
       "    <th>0.484621</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>0.905420</th>\n",
       "    <th>1.077098</th>\n",
       "    <th>0.955207</th>\n",
       "    <th>0.511867</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>0.925717</th>\n",
       "    <th>1.025889</th>\n",
       "    <th>0.958222</th>\n",
       "    <th>0.498723</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>0.863353</th>\n",
       "    <th>1.117346</th>\n",
       "    <th>0.957702</th>\n",
       "    <th>0.558898</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>5</th>\n",
       "    <th>0.838284</th>\n",
       "    <th>1.040156</th>\n",
       "    <th>0.959989</th>\n",
       "    <th>0.562133</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>6</th>\n",
       "    <th>0.791800</th>\n",
       "    <th>nan</th>\n",
       "    <th>0.960260</th>\n",
       "    <th>0.581171</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>7</th>\n",
       "    <th>0.718329</th>\n",
       "    <th>nan</th>\n",
       "    <th>0.962986</th>\n",
       "    <th>0.615464</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>8</th>\n",
       "    <th>0.776461</th>\n",
       "    <th>nan</th>\n",
       "    <th>0.963385</th>\n",
       "    <th>0.610357</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "\n",
       "  </tr>\n",
       "</table>\n",
       "\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "        \t/* Turns off some styling */\n",
       "        \tprogress {\n",
       "\n",
       "            \t/* gets rid of default border in Firefox and Opera. */\n",
       "            \tborder: none;\n",
       "\n",
       "            \t/* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "            \tbackground-size: auto;\n",
       "            }\n",
       "\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='4599' class='' max='6222', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      73.92% [4599/6222 1:10:37<24:55 0.7698]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%time learn.fit_one_cycle(10, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.save('wrn4_512')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('wrn4_512')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.data.test_dl.add_tfm(to_half)\n",
    "learn.data.valid_dl.add_tfm(to_half)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "p,t = learn.get_preds(is_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11702, 28])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_v, t_v = learn.get_preds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_np(y_pred, y_true, threshold=0.5):\n",
    "    y_pred = (y_pred>threshold).astype(int)\n",
    "    TP = (y_pred*y_true).sum(1)\n",
    "    prec = TP/(y_pred.sum(1)+1e-7)\n",
    "    rec = TP/(y_true.sum(1)+1e-7)\n",
    "    res = 2*prec*rec/(prec+rec+1e-7)\n",
    "    return res.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_v_s = p_v.sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6248)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1(p_v, t_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_v_np, t_v_np = to_np(p_v_s), to_np(t_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6248206935302782"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_np(p_v_np, t_v_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_n(y_pred, y_true, thresh, n, default=0.5):\n",
    "    threshold = default * np.ones(y_pred.shape[1])\n",
    "    threshold[n]=thresh\n",
    "    return f1_np(y_pred, y_true, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.622869969677993"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_n(p_v_np, t_v_np, 0.4, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_thresh(y_pred, y_true):\n",
    "    ths = []\n",
    "    for i in range(p_v_np.shape[1]):\n",
    "        aux = []\n",
    "        for th in np.linspace(0,1,100):\n",
    "            aux += [f1_n(p_v_np, t_v_np, th, i)]\n",
    "        ths += [np.array(aux).argmax()/100]\n",
    "    return np.array(ths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "ths = find_thresh(p_v_np, t_v_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99, 0.41, 0.3 , 0.42, 0.33, 0.37, 0.59, 0.39, 0.3 , 0.36, 0.62, 0.53, 0.31, 0.6 , 0.59, 0.46, 0.41, 0.33,\n",
       "       0.64, 0.39, 0.53, 0.36, 0.26, 0.32, 0.16, 0.38, 0.04, 0.11])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6890822265523219"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_np(p_v_np, t_v_np, ths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sub File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11702, 28)\n"
     ]
    }
   ],
   "source": [
    "preds = to_np(p.sigmoid())\n",
    "threshold = ths\n",
    "print(preds.shape)\n",
    "classes = np.array(classes)\n",
    "res = np.array([\" \".join(classes[(np.where(pp>threshold))])for pp in preds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2', '5 25', '0 5 25 21', '0 25', ..., '0 25 19', '7', '1', '0 25 23'], dtype='<U25')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.DataFrame(np.array([test_names, res]).T, columns = ['Id','Predicted'])\n",
    "frame.to_csv('my_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix indexing\n",
    "f1 = pd.read_csv('sample_submission.csv')\n",
    "f1.drop('Predicted', axis=1, inplace=True)\n",
    "f2 = pd.read_csv('my_submission.csv')\n",
    "f1 = f1.merge(f2, left_on='Id', right_on='Id', how='outer')\n",
    "f1.to_csv('my_new_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
